---
layout: posts
title: "lab 11 - 12"
categories: ["모두를 위한 머신러닝/딥러닝"]
---

### ConvNet 의 Conv 레이어 만들기

Convolutional Neural Network

- input
- feature extraction: 특징이 추출되는 부분 (conv ~ pooling)
- for classification
- Convolution: 합성곱 필터가 슬라이딩하며 이미지 부분의 특징을 읽어나감

<img width="1852" height="889" alt="image" src="https://github.com/user-attachments/assets/bb636bd0-98ba-4974-8112-77fb97b393e5" />

**FC: Fully-Connected Layer** (softmax)

Start with an image ( W x H x Depth)

한 번에 이미지 전체를 처리하는 것이 아닌 일부분만 처리 (= 필터 처리)

필터는 궁극적으로 한 값을 만들어낸다.

<img width="754" height="923" alt="image" src="https://github.com/user-attachments/assets/c0ff7f47-07d3-473c-b28f-94b83126b092" />

= Wx + b

= ReLU (Wx + b)

<img width="1425" height="913" alt="image" src="https://github.com/user-attachments/assets/59105f0b-f6be-4778-b6ec-e5bb0f8ccf00" />

7x7 사진에 대해 3x3 filter 을 적용하고 stride(= 한 번에 이동하는 칸 수) 가 1 일때

5x5 의 결과가 나온다.

<img width="1597" height="845" alt="image" src="https://github.com/user-attachments/assets/e2cf3b67-2b5e-41dd-b2fa-33623b12e7a4" />

<img width="1827" height="862" alt="image" src="https://github.com/user-attachments/assets/e728ab6f-024c-429c-83b4-f81ceca0ab4b" />

filter 을 거치면 거칠 수록 이미지가 작아진다. → 정보가 사라진다.

**Padding**: 테두리에 0으로 

→이미지가 급격하게 작아지는 것을 방지

→ 이미지의 테두리임을 알려주기 위함

<img width="610" height="775" alt="image" src="https://github.com/user-attachments/assets/3d089d68-09c3-401e-864b-d6eb558da32b" />

stride: 1 

filter: 3x3

output: 7x7 !!!

<img width="1343" height="873" alt="image" src="https://github.com/user-attachments/assets/c62d80ab-0731-4696-82d7-f62e82bf6a39" />

각각의 필터는 weight 이 다르다.

6개의 필터 → depth 는 6 이 된다.

<img width="252" height="132" alt="image" src="https://github.com/user-attachments/assets/2e4d4f9c-0d01-4ff5-8fc2-fcf3f73b7276" />

을 적용하면 output 은 (28 x 28 x 6) 이 나온다.

### CNN introduction: Max Pooling 과 Full Network

**Pooling Layer**: 간단하게는 sampling이다.

conv 에서 하나의 layer 만 뽑아낸다. → resize (sampling)

conv layer 에서 resize 하는 것을 pooling 이라고 한다.

pooling 한 값을 다시 쌓는다.

pooling layer 는 학습해야 할 가중치가 없으며 채널 수가 변하지 않는다는 특징을 갖는다.

<img width="1049" height="1011" alt="image" src="https://github.com/user-attachments/assets/56c7ffd8-be0a-4036-8a58-c14903a01577" />

**MAX POOLING**

일반적으로 이미지를 처리할 땐 각 부분의 특징을 최대로 보존하기 위한 max pooling 을 사용한다.

<img width="1678" height="761" alt="image" src="https://github.com/user-attachments/assets/d0c3ddf4-7981-4c9c-a3dd-6688ebacd560" />

**Fully Connected Layer**

: 모든 입력과 모든 출력이 서로 연결된 층

→ 입력에 있는 모든 정보가 출력에 다 영향을 줄 수 있어서 복잡한 패턴도 잘 배울 수 있다.

→ 이미지 분류, 글자 인식, 음성 인식 등 다양한 분야에서 마지막 결론을 내릴 때 많이 사용된다.

### CNN case study

Convolutional Neural Network

- LeNet-5
    
    <img width="1775" height="658" alt="image" src="https://github.com/user-attachments/assets/425ee25b-7c4f-449d-ba14-0887870e9d63" />

- AlexNet
    - 총 8 개 layer
    
    <img width="1875" height="909" alt="image" src="https://github.com/user-attachments/assets/2ac8a3fe-b922-494d-a5f1-861aab1f834b" />

    Normalization layer: 최근에는 잘 사용하지 않는다.
    
- GoogleLeNet
    
    <img width="1841" height="925" alt="image" src="https://github.com/user-attachments/assets/f0868bac-f015-4b5c-beb7-4d7254f0dcfc" />

- **`ResNet`**
    - 152 개 layer 사용
    - Fast-Forward 를 사용하여 학습 시간을 줄였다.
    
    <img width="634" height="921" alt="image" src="https://github.com/user-attachments/assets/e74bed6f-18bd-4676-9534-255f6b458e3a" />

    ResNet 은 Block 이 쌓인 구조를 가지고 있고 Block 단위로 Parameter 를 전달하기 전에 이전의 값을 더하는 방식을 취한다.
    
    <img width="923" height="623" alt="image" src="https://github.com/user-attachments/assets/756ff599-cb53-4656-86ec-c28f902b8648" />

    [**Residual Block** - 잔차 블럭]
    
    일반적으로 동일한 연산 F(x) 을 한 뒤 input x 를 더해준다. 즉, plain layer 와는 다르게 residual block 에서는 skip connection 이 존재한다.
    
    **`skip connection`(= shortcut)**: 하나의 layer 의 output을 몇 개의 layer 를 건너뛰고 다음 layer 의 input 에 추가되는 것을 의미한다. 
    
    → 각각의 layer 가 작은 정보들을 추가적으로 학습하도록 한다.
    
    **정보의 보존**: 입력값 x 이 뒤로 직접 전달되기 때문에, 층이 아무리 깊어져도 최소한 입력 정보 x 가 유지된다.
    
    **기울기 전달**: 역전파시에 더하기 연산을 통해 기울기가 감쇄되지 않고 앞쪽층으로 잘 전달된다.
    
    [relu](https://www.notion.so/2c71bbec0cf7802a98ccceb57c6d0f20?pvs=21)
    
    ### RNN
    
    Sequence data: 자연어, 영상 등 맥락이 있어야하는 것
    
    Convolution 의 경우는 x → f(x) → y 의 간단한 형태는 이러한 sequence data 를 처리하기에는 적합하지 않다.
    
    <img width="1599" height="538" alt="image" src="https://github.com/user-attachments/assets/d49721f2-3682-4d26-a3fe-d1822262da6b" />

    state 를 먼저 계산한다.
    
    <img width="1269" height="510" alt="image" src="https://github.com/user-attachments/assets/70c4f732-5a09-4b1e-be0a-faae4a9c0dc8" />

    이전의 state 값이 입력으로 사용된다.
    
     $f_{w}$ 는 모든 rnn 에 대해서 동일하다.
    
    **Vanilla RNN**
    
    <img width="1031" height="622" alt="image" src="https://github.com/user-attachments/assets/ffe518e9-53a3-46ba-9073-cac6f42a6a52" />

    one-hot encoding
    
    : character 를 vector 로 변환하는 것.
    
    $h_{t-1}$ t = 0 인 경우는 $h_{t}$를 0으로 취급한다.
    
    <img width="1038" height="801" alt="image" src="https://github.com/user-attachments/assets/3dc4a9d5-1b5c-4d4a-a605-09ca673c5337" />

    이전의 값이 뒤layer 에 영향을 미친다.
    
    softmax 를 적용하여 가장 큰 값을 취하면 다음과 같이 나온다.
    
    <img width="1012" height="837" alt="image" src="https://github.com/user-attachments/assets/5e21c184-8e08-4814-8ca5-dd847ed5a996" />

    첫 번째 l 을 예측하는 데 실패했다.
    
    cost function: 4개의 값을 더해서 평균을 낸다.
    
    **RNN applications**
    
    - Language Modeling
    - Speech Recognition
    - Machine Translation
    - Conversation Modeling / Question answering
    - Image/Video Captioning
    - Image / Video / Dance Generation
    
    <img width="1809" height="748" alt="image" src="https://github.com/user-attachments/assets/00fa2976-e434-4f07-9b5d-1f69680f7104" />

    one to many: Image Captioning
    
    Many to one: Sentiment Classification
    
    many to many 1: Machine Translation
    
    many to many 2: Video classification on frame level
